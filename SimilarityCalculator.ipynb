{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(data, features=[]):\n",
    "    \n",
    "    features.append(data['label'])\n",
    "    features.append(data['strings']['numstrings'])\n",
    "    features.append(data['strings']['avlength'])\n",
    "    features.append(hash(str(data['strings']['printabledist'])))\n",
    "    features.append(data['strings']['entropy'])\n",
    "    features.append(data['strings']['urls'])\n",
    "    features.append(data['strings']['paths'])\n",
    "    features.append(data['strings']['registry'])\n",
    "    features.append(data['strings']['MZ'])\n",
    "    features.append(data['general']['size'])\n",
    "    features.append(data['general']['vsize'])\n",
    "    features.append(data['general']['has_debug'])\n",
    "    features.append(data['general']['exports'])\n",
    "    features.append(data['general']['imports'])\n",
    "    features.append(data['general']['has_relocations'])\n",
    "    features.append(data['general']['has_resources'])\n",
    "    features.append(data['general']['has_signature'])\n",
    "    features.append(data['general']['has_tls'])\n",
    "    features.append(data['general']['symbols'])\n",
    "    features.append(hash(str(data['header']['coff']['characteristics'])))\n",
    "    features.append(data['header']['coff']['timestamp'])\n",
    "    features.append(hash(str(data['header']['optional']['subsystem'])))\n",
    "    features.append(data['header']['optional']['major_image_version'])\n",
    "    features.append(data['header']['optional']['minor_image_version'])\n",
    "    features.append(data['header']['optional']['major_linker_version'])\n",
    "    features.append(data['header']['optional']['minor_linker_version'])\n",
    "    features.append(data['header']['optional']['major_operating_system_version'])\n",
    "    features.append(data['header']['optional']['minor_operating_system_version'])\n",
    "    features.append(data['header']['optional']['major_subsystem_version'])\n",
    "    features.append(data['header']['optional']['minor_subsystem_version'])\n",
    "    features.append(data['header']['optional']['sizeof_code'])\n",
    "    features.append(data['header']['optional']['sizeof_headers'])\n",
    "    features.append(hash(str(data['imports'])))\n",
    "    \n",
    "    num_unnamed_sections = 0\n",
    "    num_write_sections = 0\n",
    "    num_zero_size_sections = 0\n",
    "    num_read_and_execute_sections = 0\n",
    "    \n",
    "    sections = data['section']['sections']\n",
    "    num_unnamed_sections = sum(1 for s in sections if s['name'] == \"\")\n",
    "    num_write_sections = sum(1 for s in sections if 'MEM_WRITE' in s['props'])\n",
    "    num_zero_size_sections = sum(1 for s in sections if s['size'] == 0)\n",
    "    num_read_and_execute_sections = sum(1 for s in sections if 'MEM_READ' in s['props'] and 'MEM_EXECUTE' in s['props'])\n",
    "    \n",
    "    features.append(num_unnamed_sections)\n",
    "    features.append(num_write_sections)\n",
    "    features.append(num_zero_size_sections)\n",
    "    features.append(num_read_and_execute_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../../media/islab/media_1/mingwai/train_features_' #1.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "malicious_list = []   # note the position of malware samples\n",
    "benign_list = []   # note the position of benign samples\n",
    "index = 0\n",
    "for i in range(6):\n",
    "    with open(path+str(i)+'.jsonl', 'rb') as datafile:\n",
    "        for data in jsonlines.Reader(datafile):\n",
    "            if data['label'] != (-1):\n",
    "                readJson(data, features)\n",
    "                \n",
    "                if data['label'] == 1:\n",
    "                    malicious_list.append(index)\n",
    "                elif data['label'] == 0:\n",
    "                    benign_list.append(index)\n",
    "                \n",
    "                index += 1\n",
    "\n",
    "features = np.reshape(features, (-1,37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "malicious_list = []   # note the position of malware samples\n",
    "benign_list = []   # note the position of benign samples\n",
    "index = 0\n",
    "with open(path+str(1)+'.jsonl', 'rb') as datafile:\n",
    "    for data in jsonlines.Reader(datafile):\n",
    "        if data['label'] != (-1):\n",
    "            readJson(data, features)\n",
    "                \n",
    "            if data['label'] == 1:\n",
    "                malicious_list.append(index)\n",
    "            elif data['label'] == 0:\n",
    "                benign_list.append(index)\n",
    "                \n",
    "            index += 1\n",
    "\n",
    "features = np.reshape(features, (-1,37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = ['numstrings', 'avg_length', 'printabledist', 'entropy', 'strings_urls', 'paths', 'registry_count', \n",
    "                 'MZ_count', 'file_size', 'vsize', 'has_debug', 'exports', 'imports', 'has_relocations', 'has_resources', \n",
    "                 'has_signature', 'has_tls', 'symbols', 'characteristics_hash', 'timestamp', 'subsystem_hash', \n",
    "                 'major_image_version', 'minor_image_version','major_linker_version', 'minor_linker_version', \n",
    "                 'major_os_version',  'minor_os_version', 'major_subsystem_version', 'minor_subsystem_version', \n",
    "                 'size_of_code', 'size_of_headers', 'import_libs_hash', 'num_unnamed_sections', 'num_write_sections', \n",
    "                 'num_zero_size_sections', 'num_read_and_execute_sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Size :  116051\n",
      "Benign sample :  52338\n",
      "Malicious sample :  63713\n"
     ]
    }
   ],
   "source": [
    "with open('dataset_similarityCal.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Label', ] + feature_group)\n",
    "    \n",
    "    for f in features:\n",
    "        writer.writerow(f)\n",
    "print('Feature Size : ', len(features))\n",
    "print('Benign sample : ', len(benign_list))\n",
    "print('Malicious sample : ', len(malicious_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_similarityCal.csv')\n",
    "data = pd.DataFrame(data)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_feature_index = {}  # Calculate duplicate feature and number\n",
    "\n",
    "for feature in feature_group:\n",
    "    mal_similar_list = {}\n",
    "    for i in range(len(malicious_list)):\n",
    "        if data[feature].iloc[malicious_list[i]] not in mal_similar_list:\n",
    "            mal_similar_list[data[feature].iloc[malicious_list[i]]] = 1\n",
    "        else:\n",
    "            mal_similar_list[data[feature].iloc[malicious_list[i]]] += 1\n",
    "    mal_feature_index[feature] = mal_similar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_feature_index = {}  # Calculate duplicate feature and number\n",
    "\n",
    "for feature in feature_group:\n",
    "    benign_similar_list = {}\n",
    "    for i in range(len(benign_list)):\n",
    "        if data[feature].iloc[benign_list[i]] not in benign_similar_list:\n",
    "            benign_similar_list[data[feature].iloc[benign_list[i]]] = 1\n",
    "        else:\n",
    "            benign_similar_list[data[feature].iloc[benign_list[i]]] += 1\n",
    "    benign_feature_index[feature] = benign_similar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_similarity_index = {}\n",
    "for i,j in mal_feature_index.items():\n",
    "    final_similarity_list = {}\n",
    "    for x,y in j.items():\n",
    "        # === Feature in Malicious Dictionary and Duplicate number >= Benign Dictionary === #\n",
    "        if (x in benign_feature_index[i]) and (y >= (benign_feature_index[i])[x]):\n",
    "            final_similarity_list[x] = y\n",
    "        elif (x not in benign_feature_index[i]):\n",
    "            final_similarity_list[x] = y\n",
    "    final_similarity_index[i] = sorted(final_similarity_list.keys())\n",
    "    #final_similarity_index[i] = sorted(final_similarity_list.items(), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_similarity_dictionary.csv', 'w', newline='') as similarity:\n",
    "    writer = csv.writer(similarity)\n",
    "    writer.writerow(['Feature Attribute', 'Duplicate Feature String', 'Repetition Rate'])\n",
    "    for i,j in final_similarity_index.items():\n",
    "        writer.writerow([i])\n",
    "        #for x,y in j[-10:-1]:     # calculate the popular value\n",
    "        #    writer.writerow(['',x,y])\n",
    "        for x,y in j[0:10]:        # calculate the unique value\n",
    "            writer.writerow(['',x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('benign_samples_similarity.csv', 'w', newline='') as similarity:\n",
    "    writer = csv.writer(similarity)\n",
    "    writer.writerow(['Feature Attribute', 'Duplicate Feature String', 'Repetition Rate'])\n",
    "    for i,j in benign_feature_index.items():\n",
    "        writer.writerow([i])\n",
    "        for x,y in j.items():\n",
    "            if y >= (len(data)*0.01):    # Filter the benign features which repetition rate >= 1% training size\n",
    "                writer.writerow(['',x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('malicious_samples_similarity.csv', 'w', newline='') as similarity:\n",
    "    writer = csv.writer(similarity)\n",
    "    writer.writerow(['Feature Attribute', 'Duplicate Feature String', 'Repetition Rate'])\n",
    "    for i,j in mal_feature_index.items():\n",
    "        writer.writerow([i])\n",
    "        for x,y in j.items():\n",
    "            if y >= (len(data)*0.01):    # Filter the malicious features which repetition rate >= 1% training size\n",
    "                writer.writerow(['',x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#benign_similarity = pd.read_csv('benign_samples_similarity.csv')\n",
    "#benign_similarity = pd.DataFrame(benign_similarity)\n",
    "#mal_similarity = pd.read_csv('malicious_samples_similarity.csv')\n",
    "#mal_similarity = pd.DataFrame(mal_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_similarity_index = {}\n",
    "for i,j in benign_feature_index.items():\n",
    "    final_similarity_list = {}\n",
    "    for x,y in j.items():\n",
    "        if y >= (len(data)*0.01):\n",
    "            if (x in mal_feature_index[i]) and (y >= (mal_feature_index[i])[x]):\n",
    "                final_similarity_list[x] = y\n",
    "            elif (x not in mal_feature_index[i]):\n",
    "                final_similarity_list[x] = y\n",
    "    final_similarity_index[i] = sorted(final_similarity_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_similarity_index = {}\n",
    "for i,j in mal_feature_index.items():\n",
    "    final_similarity_list = {}\n",
    "    for x,y in j.items():\n",
    "        if x not in benign_feature_index[i]:\n",
    "            final_similarity_list[x] = y\n",
    "            \n",
    "    final_similarity_index[i] = sorted(final_similarity_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_similarity_dictionary.csv', 'w', newline='') as similarity:\n",
    "    writer = csv.writer(similarity)\n",
    "    writer.writerow(['Feature Attribute', 'Duplicate Feature String'])\n",
    "    for i,j in final_similarity_index.items():\n",
    "        writer.writerow([i])\n",
    "        for x in j[-10:-1]:\n",
    "            writer.writerow(['',x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
